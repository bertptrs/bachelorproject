\chapter{Introduction}

Graph algorithms are in the most commonly used algorithms in computer science. Most general real-world problems can be solved by converting the problem to a graph problem and solving that using a known algorithm. As such, optimizations in graph algorithms are optimizations to various fields in computing.

In this thesis, we attempt to optimize graph algorithms using the forelem language as described in\cite{AVersatileTupleBasedOptimizationFramework}. For this thesis, we have looked at the max flow min cut problem as an example graph problem. It was first formulated in 1954 as a way of modelling Soviet railway flow\cite{HarrisRoss}. The problem asks what, given a graph $(V,E)$ in which every edge has a flow capacity $c$, is the maximum flow from a given source to a given sink. For example, the in the graph shown in \autoref{fig:simple-graph} has a maximum flow of 14, utilizing the capacities as shown.

\begin{figure}[h]
\centering
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
  thick,main node/.style={circle,fill=blue!20,draw,font=\sffamily\Large\bfseries}]

  \node[main node] (1) {s};
  \node[main node] (2) [above right of=1] {a};
  \node[main node] (3) [right of=2] {b};
  \node[main node] (4) [below right of=1] {c};
  \node[main node] (5) [right of=4] {d};
  \node[main node] (6) [above right of=5] {t};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge node {10/16} (2)
        edge node {4/4} (4)
    (2) edge node {10/12} (3)
    (3) edge [bend right] node [left] {3/3} (4)
        edge node {7/7} (6)
    (4) edge node {7/10} (5)
    (5) edge node {7/10} (6)
        edge [bend right] node [right] {0/5} (2)
    ;
\end{tikzpicture}
\caption{A simple graph with flows.}
\label{fig:simple-graph}
\end{figure}

It should be noted that the flow configuration for the maximum flow is not necessarily unique, although in this example it is. The only requirement is that for each node (excluding the source and the sink) the incoming flow is equal to the outgoing flow.

\section{Current solutions}

It should be noted that the max flow problem is not an unsolved problem. There have been several implementations, with various time and memory complexities. Early algorithms used the augmenting paths\cite{LockFreeMultithreadedMaxFlow} and construct additional routes from sources to sinks, most notably the Ford Fulkerson algorithm (see  \autoref{sec:fordfulkerson}).

Goldberg et al.\ produced a different result by constructing a preflow instead of a valid flow\cite{ANewApproachToTheMaxFlowProblem}, and pushing as much flow from the source to the sink, see \autoref{subsect:pushrelabel}. This thesis will attempt to work with the Push Lift algorithm proposed by Bo Hong \cite{LockFreeMultithreadedMaxFlow}, which allows a lock-free parallel execution of the algorithm.

\subsection{Ford-Fulkerson algorithm}
\label{sec:fordfulkerson}

The Ford-Fulkerson algorithm\cite{ford1956maximal} computes for a given directed graph of edges $(u, v, c)$ with $u$ and $v$ nodes and $c$ the capacity for the edge, the maximum ``flow'' from a given source $s$ to a sink $t$, given that the flow of an edge $e$ can never exceed its capacity. The algorithm assumes that

\begin{itemize}
\item there are no parallel edges, meaning that
$$
\forall e_1 (u_1, v_1, c_1), e_2(u_2, v_2, c_2): e_1 \neq e_2 \implies u_1 \neq u_2 \land v_1 \neq v_2
$$, and
\item there are no self loops, meaning that
$$
\nexists e (u, v, c): u = v
$$
\end{itemize}

The former condition is easily satisfied, as we can just merge two parallel edges by adding their respective capacities. The latter we can satisfy by can completely ignoring any self loops. This is valid, as self loops do not contribute to the total flow.

The algorithm works as follows. We define $f(u,v)$ and $c(u, v)$ as the flow and capacity respectively from $u$ to $v$. For all $u$ and $v$, we initialize $f(u, v)$ as zero. For all edges $(u, v, c)$, we define $c(u, v) = c$ and for all other combinations, we define $c(u, v) = 0$.

\begin{algorithm}
\caption{A pseudo-code representation of the Ford-Fulkerson algorithm}
\label{algo:ford-fulkerson}
\begin{algorithmic}

\Function{FindPath}{$source, destination, path$}
	\If{$source = destination$}
		\State \Return{$path$}
	\Else
		\ForAll{$e : e \in E \land e.u = source \land e \notin path \land f(e.u, e.v) < c(e.u, e.v)$}
			\State $newPath \gets$ \Call{FindPath}{$e.v, destination, path \cup e$}
			\If{$newPath \neq \emptyset$}
				\State \Return{$newPath$}
			\EndIf
		\EndFor
		\State \Return{$\emptyset$}
	\EndIf
\EndFunction
\State
\While{there is a useful path from $s$ to $t$}
	\State $path \gets$ \Call{FindPath}{$s, t, \emptyset$}
	\State $\delta \gets \min(c(e.u, e.v) - f(e.u, e.v) \forall e \in path$
	\ForAll{$e \in path$}
		\State $f(e.u, e.v) \gets f(e.u, e.v) + \delta$
		\State $f(e.v, e.u) \gets f(e.v, e.u) - \delta$
	\EndFor
\EndWhile
\State $maxflow \gets \sum\limits_{e : e.v = t} f(e.u, e.v)$

\end{algorithmic}
\end{algorithm}

\subsection{Push-Relabel algorithm}
\label{subsect:pushrelabel}

We define the set of nodes, $V$, and the set of edges $E$. Furthermore, we define the function $\Delta(u)$ which denotes the current excess flow\footnote{created by the preflow} at node $u$, and $F(u, v)$ and $C(u, v)$, which denote the current flow and the flow capacity from $u$ to $v$ respectively. Both start at $0$ if the edge does not exist.

A new property that is used, is the height function $H(u)$, which holds the current height for a given node. This height function is used to enforce an ordering.

The algorithm constsists of two operations. The \textsc{Push} operation pushes excess flow from a node $u$ to a connected node $v$. It is allowed only when $H(u) = H(v) + 1$. If no valid push is possible, a node must be relabeled with the \textsc{Relabel} operation. This method increases $H(u)$ to the minimum level so that a new push is allowed.

The algorithm starts by performing a satisfying push on the source node, which fully uses all outgoing edges on that node. After that, the algorithm attempts to either push the excess flow to the sink, or, if it is not possible to push, relabels the node. When there are no longer any nodes with an excess flow, the algorithm is finished and the maximum flow can be calculated by summing the flow coming into the sink $t$ or the flow going out of the source $s$. A pseudo-code implementation can be seen in \autoref{algo:push-relabel}.

\begin{algorithm}
\caption{A pseudo-code implementation of the generic Push-Relabel algorithm}
\label{algo:push-relabel}

\begin{algorithmic}
\Function{Push}{$e, amount$}
	\State $\delta \gets \min(amount, C(e.u, e.v) - F(e.u, e.v))$
	\State $\Delta(e.u) \gets \Delta(e.u) - \delta$
	\State $\Delta(e.v) \gets \Delta(e.v) + \delta$
	\State $F(e.u, e.v) \gets F(e.u, e.v) + \delta$
	\State $F(e.v, e.u) \gets F(e.v, e.u) - \delta$
\EndFunction

\State

\Function{Relabel}{$u$}
	\State $H(u) \gets \min(H(v) : F(u, v) < C(u, v)) + 1$
\EndFunction

\State

\ForAll{$e : e \in E \land e.u = s$}
	\State \Call{Push}{$e, \infty$}
\EndFor

\State

\State $H(s) \gets |V|$
\State $H(V \setminus s) \gets 0$

\State

\While{$\exists u : u \in V \setminus t \land \Delta(u) > 0$}
	\If{$\exists e : e \in E \land e.u = u \land C(e.u, e.v) > F(e.u, e.v) \land H(e.u) = H(e.v) + 1$}
		\State \Call{Push}{$e, \Delta(u)$}
	\Else
		\State \Call{Relabel}{$u$}
	\EndIf
\EndWhile

\State

\State $maxflow \gets \sum\limits_{e : e.v = t} F(e.u, e.v)$
\end{algorithmic}
\end{algorithm}

\section{The forelem language}

For this research, we will use the forelem framework \cite{AVersatileTupleBasedOptimizationFramework} to represent a general algorithm for the max flow problem. In this framework the data is expressed as several unordered sets of tuples and the algorithm can be expressed as an unordered loop with some operations over those tuples.


Once an algorithm is formatted that way, it can be materialized, transformed and concretisised into a regular programming language (such as C or Python) to be compiled and executed normally. We will discuss a number of possible the transformations here. The complete discussion can be found chapter 9 of \cite{AVersatileTupleBasedOptimizationFramework} but is out of the scope of this thesis.

\begin{algorithm}
	\caption{forelem algorithm for spare matrix dense vector multiplication}
	\label{algo:forelem-matvec}
\begin{lstlisting}[mathescape]
for (i = N; i $\geq$ 1; i--)
{
	int sum = 0;
	forelem (j; j $\in$ pA.row[i])
		sum += B[A[j].col] * A[j].value;

	C[i] = sum;
}
\end{lstlisting}
\end{algorithm}

\begin{algorithm}
\caption{\emph{forelem} algorithm for summing the products of a set of tuples}
\label{algo:forelem-sum}
\begin{lstlisting}[mathescape]
sum = 0
forelem (i; i $\in$ pA)
	sum = sum + A[i].part1 * A[i].part2
\end{lstlisting}
\end{algorithm}

First, we look at \autoref{algo:forelem-matvec}. Here, we have two dense vectors \texttt{B} and \texttt{C}, and a tuple representation of a matrix \texttt{A(column, row, value)}. We want to compute \texttt{A * B} and store the result in \texttt{C}. To do this, we iterate (in reverse) over \texttt{C} and process the tuples of the relevant row in \texttt{A}  (i.e.\ for which the row number is \texttt{i}). In order to generate executable code from this forelem-representation, we materialize these subsets into some structure. A possible solution is to create some multidimensional array, for which the outer index is our row number. However, since not every row will have the same number of non-zero elements in each row, this will lead to problems. Instead, we can create some indirection of this, which will allow for varying length arrays within the outer array. This is what we will be looking into in this thesis. The generalization of this is called Loop dependent materialization. However, since the other forms are not that applicable to this thesis, we will not be addressing them.

Another thing we may change is the structure of the tuples themselves. Consider \autoref{algo:forelem-sum}. Here, our tuples consist of two numbers, and we want to know the sum of their products. We can store them just as that: an array of tuples. However, it may be beneficial to split our array of tuples into two arrays of the two parts. Doing so may improve cache performace, depending on the access pattern. This procedure is called structure splitting.

Finally, not every element of the tuple may be necessary for the computation. Looking again at \autoref{algo:forelem-sum}, we can imagine that the tuples in \texttt{A} had an additional element, \texttt{part3}, which is not used in the computation. We can optimize this by leaving it out of the tuples, and creating a new array containing only the relevant parts, which would be smaller. We call this horizontal iteration space reduction. The smaller array might then improve cache performance. However, since in our algorithm all data is needed in some way, we chose not to implement this. Small improvements may be had by applying this to small local loops, but this would be difficult to implement manually in the absense of an automated compiler.
